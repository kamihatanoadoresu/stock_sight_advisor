# services.py
# ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆæŠ•è³‡åˆ†æãƒ»LLMé€£æºï¼‰

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

from constants import (
    LLM_MODEL_NAME,
    LLM_TEMPERATURE,
    INVESTMENT_CAUTION_TEXT,
)
from utils import (
    build_user_prompt,
    extract_decision_from_text,
    format_analysis_result,
)


class StockAdvisorService:
    """
    æ³¨ç›®æ ªãƒ»ä¿æœ‰æ ªã®åˆ†æã‚’è¡Œã†ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹
    """

    def __init__(self):
        self.llm = ChatOpenAI(
            model_name=LLM_MODEL_NAME,
            temperature=LLM_TEMPERATURE,
        )

    def analyze_stock(
        self,
        stock_name: str,
        position: str,
        additional_info: str = ""
    ) -> dict:
        """
        éŠ˜æŸ„åˆ†æã‚’è¡Œã„ã€è²·ã„æ™‚ãƒ»å£²ã‚Šæ™‚ãƒ»æ§˜å­è¦‹ã‚’åˆ¤æ–­ã™ã‚‹
        """

        system_prompt = self._build_system_prompt()
        user_prompt = build_user_prompt(
            stock_name=stock_name,
            position=position,
            additional_info=additional_info,
        )

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt),
        ]

        response = self.llm.invoke(messages)
        response_text = response.content

        decision_key = extract_decision_from_text(response_text)

        return format_analysis_result(
            response_text=response_text,
            decision_key=decision_key,
        )

    def _build_system_prompt(self) -> str:
        """
        ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå®‰å…¨æ€§ãƒ»ä¸€è²«æ€§æ‹…ä¿ï¼‰
        """
        return f"""
ã‚ãªãŸã¯æ ªå¼æŠ•è³‡ã®ä¸€èˆ¬çš„ãªæƒ…å ±æä¾›ã‚’è¡Œã†ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

ä»¥ä¸‹ã®åˆ¶ç´„ã‚’å¿…ãšå®ˆã£ã¦ãã ã•ã„ã€‚
- ç‰¹å®šéŠ˜æŸ„ã®è³¼å…¥ãƒ»å£²å´ã‚’æ–­å®šçš„ã«æŒ‡ç¤ºã—ãªã„
- å¿…ãšåˆ¤æ–­ã®æ ¹æ‹ ã‚’èª¬æ˜ã™ã‚‹
- å°†æ¥äºˆæ¸¬ã¯ä¸ç¢ºå®Ÿã§ã‚ã‚‹ã“ã¨ã‚’æ˜ç¤ºã™ã‚‹
- æŠ•è³‡åˆ¤æ–­ã¯è‡ªå·±è²¬ä»»ã§ã‚ã‚‹æ—¨ã‚’å«ã‚ã‚‹

{INVESTMENT_CAUTION_TEXT}
""".strip()



# â†“ã“ã“ã‹ã‚‰---------------------------------
# ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»åˆ†æãƒ­ã‚¸ãƒƒã‚¯ï¼ˆServiceå±¤ï¼‰

import re
import pickle
import os
from datetime import datetime, timedelta

import pandas as pd
import requests
import yfinance as yf
from bs4 import BeautifulSoup
import streamlit as st

from constants import CACHE_FILE_PATH, CACHE_EXPIRY_DAYS


class IPOStockService:
    """
    æœ‰åŠ›IPOéŠ˜æŸ„ã‚’æŠ½å‡ºã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹
    """

    # =========================
    # 1. JPX IPOä¸€è¦§å–å¾—
    # =========================
    def get_jpx_ipo_list_multi_year(self, years: int = 5) -> pd.DataFrame:
        base_url = "https://www.jpx.co.jp/listing/stocks/new/"
        suffix_list = [
            "index.html",
            "00-archives-01.html",
            "00-archives-02.html",
            "00-archives-03.html",
            "00-archives-04.html",
        ]

        records = []

        for i in range(min(years, len(suffix_list))):
            url = base_url + suffix_list[i]

            try:
                r = requests.get(
                    url,
                    headers={"User-Agent": "Mozilla/5.0"},
                    timeout=10,
                )
                r.encoding = r.apparent_encoding
                soup = BeautifulSoup(r.text, "html.parser")

                table = soup.find("table")
                if table is None:
                    continue

                rows = table.find_all("tr")[2:]

                idx = 0
                while idx < len(rows) - 1:
                    tr1 = rows[idx]
                    tr2 = rows[idx + 1]

                    tds1 = tr1.find_all("td")
                    tds2 = tr2.find_all("td")

                    try:
                        listed_date = tds1[0].get_text(strip=True).split("ï¼ˆ")[0]
                        company = tds1[1].find("a").get_text(strip=True)
                        code = tds1[2].get_text(strip=True)
                        market = tds2[0].get_text(strip=True)

                        price_text = tds2[3].get_text(strip=True) if len(tds2) > 3 else ""
                        if "ï½" in price_text:
                            price_text = price_text.split("ï½")[-1]

                        public_price = (
                            int(price_text.replace(",", ""))
                            if price_text.replace(",", "").isdigit()
                            else None
                        )

                        records.append(
                            {
                                "ä¸Šå ´æ—¥": listed_date,
                                "å¸‚å ´": market,
                                "è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰": code,
                                "ä¼æ¥­å": company,
                                "å…¬å‹Ÿä¾¡æ ¼": public_price,
                            }
                        )
                    except Exception:
                        pass

                    idx += 2

            except Exception:
                continue
        return pd.DataFrame(records)

    # =========================
    # 2. ç¾åœ¨æ ªä¾¡å–å¾—ï¼ˆyfinanceï¼‰
    # =========================
    def get_current_prices(self, df: pd.DataFrame) -> pd.DataFrame:
        df = df.copy()
        df["ç¾åœ¨æ ªä¾¡"] = None

        for i in df.index:
            code = df.at[i, "è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰"].zfill(4) + ".T"
            try:
                ticker = yf.Ticker(code)
                data = ticker.history(period="1d")

                if not data.empty:
                    df.at[i, "ç¾åœ¨æ ªä¾¡"] = round(data["Close"].iloc[-1])
            except Exception:
                pass

        return df

    # =========================
    # 3. æ™‚ä¾¡ç·é¡å–å¾—ï¼ˆIR BANKï¼‰
    # =========================
    def get_market_cap(self, code: str) -> float | None:
        try:
            url = f"https://irbank.net/{code}/cap"
            r = requests.get(
                url,
                headers={"User-Agent": "Mozilla/5.0"},
                timeout=10,
            )
            soup = BeautifulSoup(r.content, "html.parser")

            tds = soup.select("table#tbc tbody tr td")
            for td in tds:
                text = td.get_text(strip=True)
                match = re.match(r"(\d+)(å„„)(\d+)?(ä¸‡)?", text)
                if match:
                    oku = int(match.group(1))
                    man = int(match.group(3)) if match.group(3) else 0
                    return oku + man / 10000

            return None

        except Exception:
            return None

    # =========================
    # 4. ã‚ªãƒ¼ãƒŠãƒ¼å‰µæ¥­ç¤¾é•·åˆ¤å®š
    # =========================
    def is_owner_ceo(self, code: str) -> bool:
        try:
            url = f"https://irbank.net/{code}/officer"
            r = requests.get(
                url,
                headers={"User-Agent": "Mozilla/5.0"},
                timeout=10,
            )
            soup = BeautifulSoup(r.content, "html.parser")

            for tr in soup.find_all("tr"):
                tds = tr.find_all("td")
                if len(tds) >= 2:
                    role_text = tds[1].get_text(strip=True)
                    match = re.search(r"\(([\d.]+)%\)", role_text)
                    ratio = float(match.group(1)) if match else 0.0

                    if "å–ç· å½¹" in role_text and ratio >= 40:
                        return True

            return False

        except Exception:
            return False

    # =========================
    # 5. æœ‰åŠ›IPOæŠ½å‡ºï¼ˆå…¥å£ï¼‰
    # =========================
    def get_promising_ipos(self) -> pd.DataFrame:
        """
        æœ‰åŠ›IPOéŠ˜æŸ„ã‚’æŠ½å‡ºã™ã‚‹
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚ã‚Œã°ãã‚Œã‚’è¿”ã—ã€ãªã‘ã‚Œã°æ–°è¦å–å¾—ã™ã‚‹
        """
        # JPX IPOä¸€è¦§å–å¾—
        df = self.get_jpx_ipo_list_multi_year(years=5)

        if df.empty or "è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰" not in df.columns:
            return pd.DataFrame(
                columns=[
                    "è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰",
                    "ä¼æ¥­å",
                    "ä¸Šå ´æ—¥",
                    "ç¾åœ¨æ ªä¾¡",
                    "å…¬å‹Ÿä¾¡æ ¼",
                    "æ™‚ä¾¡ç·é¡",
                ]
            )

        # ç¾åœ¨æ ªä¾¡å–å¾—
        with st.spinner(f"ğŸ“Š {len(df)}ä»¶ã®IPOéŠ˜æŸ„ã‹ã‚‰æ ªä¾¡ã‚’å–å¾—ä¸­..."):
            df = self.get_current_prices(df)

        # æ™‚ä¾¡ç·é¡å–å¾—
        with st.spinner("ğŸ’° æ™‚ä¾¡ç·é¡ã‚’å–å¾—ä¸­..."):
            df["æ™‚ä¾¡ç·é¡"] = df["è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰"].apply(self.get_market_cap)

        # ã‚ªãƒ¼ãƒŠãƒ¼å‰µæ¥­ç¤¾é•·åˆ¤å®š
        with st.spinner("ğŸ‘” ã‚ªãƒ¼ãƒŠãƒ¼å‰µæ¥­ç¤¾é•·ã‚’åˆ¤å®šä¸­..."):
            df["ã‚ªãƒ¼ãƒŠãƒ¼å‰µæ¥­ç¤¾é•·"] = df["è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰"].apply(self.is_owner_ceo)

        # ä¸Šå ´å¹´ã‚’æŠ½å‡º
        df["ä¸Šå ´å¹´"] = df["ä¸Šå ´æ—¥"].str[:4].astype(int)

        # ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
        df_filtered = df.copy()

        # ä¸Šå ´å¹´ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆç¾åœ¨ã‹ã‚‰10å¹´ä»¥å†…ï¼‰
        year_limit = datetime.now().year - 10
        df_filtered = df_filtered[df_filtered["ä¸Šå ´å¹´"] >= year_limit]

        # å…¬å‹Ÿä¾¡æ ¼ã‚ã‚Š
        df_filtered = df_filtered[df_filtered["å…¬å‹Ÿä¾¡æ ¼"].notnull()]

        # ç¾åœ¨æ ªä¾¡ã‚ã‚Š
        df_filtered = df_filtered[df_filtered["ç¾åœ¨æ ªä¾¡"].notnull()]

        # ç¾åœ¨æ ªä¾¡ < å…¬å‹Ÿä¾¡æ ¼
        df_filtered = df_filtered[df_filtered["ç¾åœ¨æ ªä¾¡"] < df_filtered["å…¬å‹Ÿä¾¡æ ¼"]]

        # æ™‚ä¾¡ç·é¡ãŒæ•°å€¤ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        df_filtered["æ™‚ä¾¡ç·é¡"] = pd.to_numeric(df_filtered["æ™‚ä¾¡ç·é¡"], errors="coerce")
        df_filtered = df_filtered[df_filtered["æ™‚ä¾¡ç·é¡"].notnull()]

        # æ™‚ä¾¡ç·é¡ãŒ 30 ä»¥ä¸Š 700 ä»¥ä¸‹
        df_filtered = df_filtered[
            (df_filtered["æ™‚ä¾¡ç·é¡"] >= 30) & (df_filtered["æ™‚ä¾¡ç·é¡"] <= 700)
        ]

        # ã‚ªãƒ¼ãƒŠãƒ¼å‰µæ¥­ç¤¾é•·ãŒ True
        df_filtered = df_filtered[df_filtered["ã‚ªãƒ¼ãƒŠãƒ¼å‰µæ¥­ç¤¾é•·"] == True]

        # å¿…è¦ãªåˆ—ã®ã¿è¿”ã™
        result = df_filtered[
            ["è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰", "ä¼æ¥­å", "ä¸Šå ´æ—¥", "ç¾åœ¨æ ªä¾¡", "å…¬å‹Ÿä¾¡æ ¼", "æ™‚ä¾¡ç·é¡"]
        ].reset_index(drop=True)

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        self.save_cache(result)

        return result

    # =========================
    # 6. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
    # =========================
    def save_cache(self, df: pd.DataFrame) -> None:
        """ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            cache_data = {
                "data": df,
                "timestamp": datetime.now(),
            }
            with open(CACHE_FILE_PATH, "wb") as f:
                pickle.dump(cache_data, f)
        except Exception as e:
            st.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    def load_cache(self) -> tuple[pd.DataFrame | None, datetime | None]:
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        Returns: (DataFrame, ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—) ã¾ãŸã¯ (None, None)
        """
        if not os.path.exists(CACHE_FILE_PATH):
            return None, None

        try:
            with open(CACHE_FILE_PATH, "rb") as f:
                cache_data = pickle.load(f)
            return cache_data.get("data"), cache_data.get("timestamp")
        except Exception as e:
            st.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return None, None

    def is_cache_valid(self, timestamp: datetime | None) -> bool:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹æœŸé™å†…ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯"""
        if timestamp is None:
            return False

        expiry_date = timestamp + timedelta(days=CACHE_EXPIRY_DAYS)
        return datetime.now() < expiry_date